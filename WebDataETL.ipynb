{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNH7ZTcGj1UXEjyKIBCrQ8z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkapriyathecoderinprogress/WebDataETLPipeline/blob/main/WebDataETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vZuuxoHSUsYH",
        "outputId": "468485e7-6da3-4586-ba8b-870ed93851dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4 nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgPNs-n2Va6x",
        "outputId": "1c92c7dc-6cb3-420e-b35c-27bf252bb74e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WebScraper:\n",
        "  def __init__(self,url):\n",
        "    self.url = url\n",
        "\n",
        "  def extract_article_text(self):\n",
        "    response = requests.get(self.url)\n",
        "    html_content = response.content\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "    article_text = soup.get_text()\n",
        "    return article_text"
      ],
      "metadata": {
        "id": "4aODlge8Wzyp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextProcessor:\n",
        "  def __init__(self,nltk_stopwords):\n",
        "    self.nltk_stopwords = nltk_stopwords\n",
        "\n",
        "  def tokenize_and_clean(self,text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word.lower() for word in words if word.isalpha() and word.lower() not in self.nltk_stopwords]\n",
        "    return filtered_words"
      ],
      "metadata": {
        "id": "5WKcw5DXZ37d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ETLPipeline:\n",
        "  def __init__(self,url):\n",
        "    self.url = url\n",
        "    self.nltk_stopwords = set(stopwords.words(\"english\"))\n",
        "\n",
        "  def run(self):\n",
        "    scraper = WebScraper(self.url)\n",
        "    article_text = scraper.extract_article_text()\n",
        "\n",
        "    processor = TextProcessor(self.nltk_stopwords)\n",
        "    filtered_words = processor.tokenize_and_clean(article_text)\n",
        "\n",
        "    word_freq = Counter(filtered_words)\n",
        "    df = pd.DataFrame(word_freq.items(), columns=[\"Words\", \"Frequencies\"])\n",
        "    df = df.sort_values(by=\"Frequencies\", ascending=False)\n",
        "    return df"
      ],
      "metadata": {
        "id": "KpfjF5CJafLM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  article_url = \"https://www.investopedia.com/terms/m/montecarlosimulation.asp\"\n",
        "  pipeline = ETLPipeline(article_url)\n",
        "  result_df = pipeline.run()\n",
        "  print(result_df.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc-e9AfVbfDi",
        "outputId": "76ac6712-42d4-4108-b9e1-b16fbc7111f4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Words  Frequencies\n",
            "1          carlo           56\n",
            "0          monte           53\n",
            "80    simulation           35\n",
            "211        price           21\n",
            "63          best           21\n",
            "333        daily           20\n",
            "147       random           15\n",
            "149         used           14\n",
            "82          risk           13\n",
            "84   simulations           13\n",
            "59         rates           12\n",
            "46     financial           12\n",
            "138  probability           12\n",
            "18          view           12\n",
            "332     periodic           11\n",
            "215          use           11\n",
            "334      returns           10\n",
            "34      personal            9\n",
            "355     function            9\n",
            "193      average            9\n"
          ]
        }
      ]
    }
  ]
}